#value is the data(1s & 0s) and Var1=subj, Var2=lens cond
kable(tibble(
"test"    = SlantYN_cochran$method.test,
"Q"       = SlantYN_cochran$statistic,
"df"      = SlantYN_cochran$parameter,
"p-value" = format(SlantYN_cochran$p.value, scientific = TRUE)
))
#Note: Q gets reported intext as Chi squared because it is based on a chi-squared
# distribution.
# A routine to iterate over pairs of tests
map2_df(
c("SL_cont_square","SL_cont_phone","SL_cont_square","SL_exp_square","SL_cont_square","SL_cont_phone"),
c("SL_exp_square","SL_exp_phone", "SL_cont_phone","SL_exp_phone","SL_exp_phone","SL_exp_square" ),
run_mcnemar_test_and_table,
data = SlantYN
) %>% # takes this output and puts it into next
#Correct p values. this is performed after because we need all of the p values in
# one matrix to perform the correction
mutate( `Corrected P Value` = p.adjust(`Original P Value`, method = "fdr") ) %>% #adding a column for corrected p value
kable() #makes table come out as html
conds = c("SLr_exp_square", "SLl_exp_square", "SLr_exp_phone", "SLl_exp_phone") #defines condition we itterate over
conds %>% #inputs conditions into next function
map_df(                    #iterates over conditions in first input(i.e.cond)
do_binomial_test,        #runs function at the top
thisdata = SlantD,
p = 0.05,
alternative = "two.sided"
) %>%
mutate(
condition   = conds,
percent_yes = percent_format(accuracy = 0.001)(estimate), #percent_format is a function to format
) %>%
#select columns you want in table
select(condition, percent_yes)%>%
kable()
SlantD_q = melt(data.matrix(SlantD)) #reshape the data
SlantD_cochran = cochran.qtest(value ~ Var2 | Var1, data = SlantD_q)
#value is the data(1s & 0s) and Var1=subj, Var2=lens cond
kable(tibble(
"test"    = SlantD_cochran$method.test,
"Q"       = SlantD_cochran$statistic,
"df"      = SlantD_cochran$parameter,
"p-value" = format(SlantD_cochran$p.value, scientific = TRUE)
))
#Note: Q gets reported intext as Chi squared because it is based on a chi-squared
# distribution.
conds = c("SLr_cont_square", "SLl_cont_square", "SLr_cont_phone", "SLl_cont_phone") #defines condition we iterate over
conds %>% #inputs conditions into next function
map_df(                    #iterates over conditions in first input(i.e.cond)
do_binomial_test,        #runs function at the top
thisdata = SlantD_control,
p = 0.05,
alternative = "two.sided"
) %>%
mutate(
condition   = conds,
percent_yes = percent_format(accuracy = 0.001)(estimate), #percent_format is a function to format
) %>%
#select columns you want in table
select(condition, percent_yes)%>%
kable()
knitr::opts_chunk$set(echo = TRUE)
#Load in packages
library(stats)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(reshape2)#used for Cochran Q
library(psych)#used for Cochran Q
library(RVAideMemoire)#Cochran Q
library(ez) # within subjects anova
library(knitr) # makes nicely formatted tables
library(scales) # nicely formatted numbers
library(car) #used for Levene test for homoginety
library(lmPerm)
# This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
# When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
#load the data
ShapeRatio       = read.csv(file='./data/ShapeRatio.csv',header=TRUE) # shape ratio drawn
ShapeRatio_anova = read.csv(file='./data/ShapeRatio_anova.csv',header=TRUE) # shape ratio for ANOVA
SlantYN          = read.csv(file='./data/SlantYN.csv',header=TRUE) # Y/N if people saw a slant
SlantD           = read.csv(file='./data/SlantD.csv',header=TRUE) # direction of slant perceived just experimental conditions
SlantD_control   = read.csv(file='./data/SlantD_control_cond.csv',header=TRUE) # direction of slant perceived just control conditions
#LOAD IN DATA from controlled experiment
# magnification, actual shape data, and estimated shape date created by fitting a third order polynomial to the shape estimates generated from the slant data
ShapeU_actual_and_fit = read.csv(file='ShapeU_actual_and_fit.csv',header=TRUE)
knitr::opts_chunk$set(echo = TRUE)
#Load in packages
library(stats)
library(tidyverse)
library(ggpubr)
library(rstatix)
library(reshape2)#used for Cochran Q
library(psych)#used for Cochran Q
library(RVAideMemoire)#Cochran Q
library(ez) # within subjects anova
library(knitr) # makes nicely formatted tables
library(scales) # nicely formatted numbers
library(car) #used for Levene test for homoginety
library(lmPerm)
# This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
# When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
#load the data
ShapeRatio       = read.csv(file='./data/ShapeRatio.csv',header=TRUE) # shape ratio drawn
ShapeRatio_anova = read.csv(file='./data/ShapeRatio_anova.csv',header=TRUE) # shape ratio for ANOVA
SlantYN          = read.csv(file='./data/SlantYN.csv',header=TRUE) # Y/N if people saw a slant
SlantD           = read.csv(file='./data/SlantD.csv',header=TRUE) # direction of slant perceived just experimental conditions
SlantD_control   = read.csv(file='./data/SlantD_control_cond.csv',header=TRUE) # direction of slant perceived just control conditions
#LOAD IN DATA from controlled experiment
# magnification, actual shape data, and estimated shape date created by fitting a third order polynomial to the shape estimates generated from the slant data
ShapeU_actual_and_fit = read.csv(file='./data/ShapeU_actual_and_fit.csv',header=TRUE)
ShapeH_actual_and_fit = read.csv(file='./data/ShapeH_actual_and_fit.csv',header=TRUE)
ShapeV_actual_and_fit = read.csv(file='./data/ShapeV_actual_and_fit.csv',header=TRUE)
#Slant responses
#Used for running correlations between magnification and the slant
r_format_slantV = read.csv(file='./data/r_format_slantV.csv',header=TRUE)
r_format_slantH = read.csv(file='./data/r_format_slantH.csv',header=TRUE)
################# FUNCTION USED FOR MEAN MEDIAN CREATION
#Function for a mean and median table. Input a data matrix with responeses for each lens
mean_and_median_table = function(data) {
N = 40
Mean_all   = tidy(apply(data,2,mean)) #I need tidy to create the table/data frame thing
Median_all = apply(data,2,median)
SD_all     = apply(data,2,sd)
CI_all     = (1.96 * SD_all) / sqrt(N)
rename(Mean_all, M = x) %>% #rename mean column to M
mutate(Mean_all, Mdn = Median_all, CI_95 = CI_all) %>% #add column with median values named Mdn
select(names,M,Mdn,CI_95) %>% #for some reason the original x column is still there so I will select out the variables I want
kable() #makes the table output in the html
}
################ FUNCTIONS FOR McNemar TESTS
# Run Mcnemar test, calculate effect size
mcnemar_test = function(a, b) {
this_test = mcnemar.test(a,b, correct = TRUE)
this_test_tidy     = tidy(this_test)
this_test_tidy_chi = rename(this_test_tidy, chi_sqared = statistic) #rename the statistic chi_squared
#effect size - odds ratio #there is not a good consensus on the best effect
#size measure
# It is the control conditions divided by experimental. Except when the experimental
# and control conditions are directly compared, then the square condition is
# divided by the phone condition.
Odds_ratio = (sum(a) / sum(b)) #ratio of the people who said yes to Lens1 vs Lens2
#add columns to store the effect size
mutate(this_test_tidy_chi, Odds_ratio = Odds_ratio)
}
# Input name of lens conditions you want to compare, use the function above to add
# the desired columns and run the wilcox test # %>% puts current ouput as first next input
run_mcnemar_test_and_table <- function (thiscond1, thiscond2, data) {
mcnemar_test(data[,thiscond1], data[,thiscond2])%>%  #run previous function to run the statistical test
mutate(Comparison = str_c(thiscond1, " vs ", thiscond2)) %>% #add column with comparison
select(Comparison,chi_sqared,df = parameter, Odds_ratio,`Original P Value` = p.value) #keeps only variables mentioned
}
########### PERCENT AND BINOMIAL CI FOR PERCENT FOR Y/N QUESTION
# These results match with the MATLAB error bar calculations that are being plotted.
do_binomial_test <- function(cond, thisdata, ...) { #... allows extra variables to pass to the binomial function
binom.test( sum(thisdata[,cond]) , n = length(thisdata[,cond]), ... ) %>%
tidy()
}
##########################################
############## FUNCTION THAT RUNS A PAIRED T TEST
# T-tests and effect size (Cohan's d)
make_ttest_table = function(a, b, mstr1,mstr2) {
this_test = t.test(a,b,paired = TRUE, alterative = "two.sided")
this_test_tidy   = tidy(this_test)
this_test_tidy2 = rename(this_test_tidy, t = statistic, df = parameter)
#calculate effect size - Cohan's D
# I need to create a vect of of the data and a list of factors to run the test
y = c(a,b)
group = factor(rep(c(mstr1,mstr2),each = 20))
df = data.frame(group,y) #create a data frame with both values
# Try to get Cohen's D but if it fails, spit out an NA
d = tryCatch(
{
# the output includes the upper and lower confidence intervals,
# but we will just use d
cohen.d(y, group, data = df)$cohen.d[2]
},
error = function(cond) {
return(NA)
}
)
#add columns
mutate(this_test_tidy2,Cohans_d = d)
}
# Input name of the models that we want compared and it will run the function above
run_ttest_test <- function (mstr1, mstr2, data) {
test_out = make_ttest_table(data[,mstr1], data[,mstr2], mstr1, mstr2)  #run previous function that runs t test
mutate(test_out, Comparison = str_c(mstr1, " vs ", mstr2)) %>% #add column with comparison
select(Comparison,t,df,Cohans_d,"Original P Value" = p.value) #keeps only variables mentioned
}
############## FUNCTION RUNS AN UNPAIRD T TEST ##########################
# T-tests and effect size (Cohan's d)
make_unpaired_ttest_table = function(a, b, mstr1,mstr2) {
this_test = t.test(a,b,paired = FALSE, alterative = "two.sided")
this_test_tidy   = tidy(this_test)
this_test_tidy2 = rename(this_test_tidy, t = statistic, df = parameter)
#calculate effect size - Cohan's D
# I need to create a vect of of the data and a list of factors to run the test
y = c(a,b)
group = factor(rep(c(mstr1,mstr2),each = 20))
df = data.frame(group,y) #create a data frame with both values
# Try to get Cohen's D but if it fails, spit out an NA
d = tryCatch(
{
# the output includes the upper and lower confidence intervals,
# but we will just use d
cohen.d(y, group, data = df)$cohen.d[2]
},
error = function(cond) {
return(NA)
}
)
#add columns
mutate(this_test_tidy2,Cohans_d = d)
}
# Input name of the models that we want compared and it will run the function above
run_unpaired_ttest_test <- function (mstr1, mstr2, data) {
test_out = make_unpaired_ttest_table(data[,mstr1], data[,mstr2], mstr1, mstr2)  #run previous function that runs t test
mutate(test_out, Comparison = str_c(mstr1, " vs ", mstr2)) %>% #add column with comparison
select(Comparison,t,df,Cohans_d,"Original P Value" = p.value) #keeps only variables mentioned
}
#################### FUNCTION THAT CALCULATES ADJUSTED R^2
calculate_r2 = function(thisdata,freeparameter){
subj_vector = unique(thisdata$subj)# vector of subj numbers
#an empty data frame to store the data
r2_vals = data.frame(subj = subj_vector, r2 = rep(NA,length(subj_vector)), r2_adjusted = rep(NA,length(subj_vector)))
for (thissubj in subj_vector) #loop over the subjects. thissubj takes the subject value
{
#extracts data needed from one subject
thissubjdata = subset(thisdata, subj==thissubj)
#calculate r^2 for one subject
#we will only use the r^2 from this data and not the r^2 adjusted.
results.lm = lm(actual ~ model, data=thissubjdata) #calculates
r_squared = summary(results.lm)$r.squared #r squared
#R^2 adjusted using the McNemar’s formula
#Note: there were 20 participants
r_squared_adj = 1 - (( (1 - r_squared) * (20-1) ) / (20 - freeparameter - 1))
#store adjusted and not adjusted value into a data frame
r2_vals[thissubj, 2] = summary(results.lm)$r.squared
r2_vals[thissubj, 3] = r_squared_adj
r2_vals[thissubj, 4] = summary(results.lm)$coefficients[2,4]
}
return(r2_vals) # I need the return in order to get this value out of the function
}
###############################################################################
############ FUNCTION THAT CALCULATES RMSE
#this functions will calculate RMSE for each subject and store the value in a matrix.
# each subject has mulitple data values.
calculate_rmse = function(thisdata){
subj_vector = unique(thisdata$subj)# vector of subj numbers
#an empty data frame to store the data
RMSE_vals = data.frame(subj = subj_vector, rmse = rep(NA,length(subj_vector)))
for (thissubj in subj_vector) #loop over the subjects. thissubj takes the subject value
{
#extracts data needed from one subject
thissubjdata = subset(thisdata, subj==thissubj)
#calculate RMSE for one subject
result = sqrt(mean((thissubjdata$actual - thissubjdata$model)^2))
#store the RMSE value for each subject
RMSE_vals[thissubj, 2] = result
}
return(RMSE_vals) # I need the return in order to get this value out of the function
}
##########################################
##################### FUNCTION TO CALCULATE CORRELATION COEFFICIENT
# this function will be used to caluclate the correlation coefficient.
calculate_r = function(thisdata){
subj_vector = unique(thisdata$subj)# vector of subj numbers
#an empty data frame to store the data
r_vals = data.frame(subj = subj_vector, r = rep(NA,length(subj_vector)), p_val = rep(NA,length(subj_vector)))
for (thissubj in subj_vector) #loop over the subjects. thissubj takes the subject value
{
#extracts data needed from one subject
thissubjdata = subset(thisdata, subj==thissubj)
#calculate r for each participant
res = cor.test(thissubjdata$mag,thissubjdata$actual,method = "pearson")
#store adjusted and not adjusted value into a data frame
r_vals[thissubj, 2] = res$estimate
r_vals[thissubj, 3] = res$p.value
}
return(r_vals) # I need the return in order to get this value out of the function
}
########################################
mean_and_median_table(ShapeRatio)
ShapeRatio_anova$subj <- as.factor(ShapeRatio_anova$subj)
ShapeRatio_anova$lens <- as.factor(ShapeRatio_anova$lens)
ShapeRatio_anova$obj  <- as.factor(ShapeRatio_anova$obj)
fitF <- ezANOVA(data = ShapeRatio_anova, dv = resp, within = c(lens,obj), wid = subj)
ShapeRatio_anova_fit = fitF$ANOVA
##making sure that the other way of doing an ANOVA also works.
#model = aov(shape_ratio~condition+Error(subj),data= ShapeRatio_anova)
#summary(model)
kable(ShapeRatio_anova_fit)
res_leven = leveneTest(resp ~ lens*obj , data = ShapeRatio_anova)
res_leven
# it is significant which means that there is different levels of variance
#in the groups. So, we will run a permutation ANOVA which are not based on
#assumptions of homogeneity to see if we get the same results.
res = aovp(resp ~ lens*obj, data = ShapeRatio_anova)
summary(res)
# The same results are significant so we will just present the results of the
# original ANOVA in text.
conds = c("SL_exp_square", "SL_cont_square", "SL_exp_phone", "SL_cont_phone") #defines condition we itterate over
conds %>% #inputs conditions into next function
map_df(                    #iterates over conditions in first input(i.e.cond)
do_binomial_test,        #runs function at the top
thisdata = SlantYN,
p = 0.05,
alternative = "two.sided"
) %>%
mutate(
condition   = conds,
percent_yes = percent_format(accuracy = 0.001)(estimate), #percent_format is a function to format
) %>%
#select columns you want in table
select(condition, percent_yes)%>%
kable()
SlantYN_q = melt(data.matrix(SlantYN)) #reshape the data
SlantYN_cochran = cochran.qtest(value ~ Var2 | Var1, data = SlantYN_q)
#value is the data(1s & 0s) and Var1=subj, Var2=lens cond
kable(tibble(
"test"    = SlantYN_cochran$method.test,
"Q"       = SlantYN_cochran$statistic,
"df"      = SlantYN_cochran$parameter,
"p-value" = format(SlantYN_cochran$p.value, scientific = TRUE)
))
#Note: Q gets reported intext as Chi squared because it is based on a chi-squared
# distribution.
# A routine to iterate over pairs of tests
map2_df(
c("SL_cont_square","SL_cont_phone","SL_cont_square","SL_exp_square","SL_cont_square","SL_cont_phone"),
c("SL_exp_square","SL_exp_phone", "SL_cont_phone","SL_exp_phone","SL_exp_phone","SL_exp_square" ),
run_mcnemar_test_and_table,
data = SlantYN
) %>% # takes this output and puts it into next
#Correct p values. this is performed after because we need all of the p values in
# one matrix to perform the correction
mutate( `Corrected P Value` = p.adjust(`Original P Value`, method = "fdr") ) %>% #adding a column for corrected p value
kable() #makes table come out as html
conds = c("SLr_exp_square", "SLl_exp_square", "SLr_exp_phone", "SLl_exp_phone") #defines condition we itterate over
conds %>% #inputs conditions into next function
map_df(                    #iterates over conditions in first input(i.e.cond)
do_binomial_test,        #runs function at the top
thisdata = SlantD,
p = 0.05,
alternative = "two.sided"
) %>%
mutate(
condition   = conds,
percent_yes = percent_format(accuracy = 0.001)(estimate), #percent_format is a function to format
) %>%
#select columns you want in table
select(condition, percent_yes)%>%
kable()
SlantD_q = melt(data.matrix(SlantD)) #reshape the data
SlantD_cochran = cochran.qtest(value ~ Var2 | Var1, data = SlantD_q)
#value is the data(1s & 0s) and Var1=subj, Var2=lens cond
kable(tibble(
"test"    = SlantD_cochran$method.test,
"Q"       = SlantD_cochran$statistic,
"df"      = SlantD_cochran$parameter,
"p-value" = format(SlantD_cochran$p.value, scientific = TRUE)
))
#Note: Q gets reported intext as Chi squared because it is based on a chi-squared
# distribution.
conds = c("SLr_cont_square", "SLl_cont_square", "SLr_cont_phone", "SLl_cont_phone") #defines condition we iterate over
conds %>% #inputs conditions into next function
map_df(                    #iterates over conditions in first input(i.e.cond)
do_binomial_test,        #runs function at the top
thisdata = SlantD_control,
p = 0.05,
alternative = "two.sided"
) %>%
mutate(
condition   = conds,
percent_yes = percent_format(accuracy = 0.001)(estimate), #percent_format is a function to format
) %>%
#select columns you want in table
select(condition, percent_yes)%>%
kable()
#Calculate the correlation coefficient for each participant between the magnitude
#of magnification and the mean slant responses.
#HORIZONTAL slant
output_cor_slantH = calculate_r(r_format_slantH)
#VERTICAL slant
output_cor_slantV = calculate_r(r_format_slantV)
# reformat model data frames so that the corrected r^2 values are all in the same
# data frame.
slantH  = output_cor_slantH$r
slantV  = output_cor_slantV$r
r_slant_all = data.frame(slantH,slantV) #r squared values for all participants for H & V slant responses
kable(r_slant_all) # prints the r^2 values
mean_and_median_table(r_slant_all) # prints the mean median and 95% CI
#run an unpaired t test to establish if the r values are statistically significantly
#different from zero
zero_array = integer(length(slantV)) #list of zeros the length of the data
#add zeros to the table
r_slant_all_w0 = mutate(r_slant_all,zeros = zero_array)
# A routine to iterate over pairs of tests
map2_df(
c("slantH","slantV"),
c("zeros","zeros"),
run_unpaired_ttest_test,
data = r_slant_all_w0
) %>% #%>% takes this output and puts it into next
#
kable() #makes table come out as html
#Calculate the correlation coefficient for each participant between the magnitude
#of magnification and the mean shape responses.
#HORIZONTAL shape
output_cor_shapeH = calculate_r(ShapeH_actual_and_fit)
#VERTICAL shape
output_cor_shapeV = calculate_r(ShapeV_actual_and_fit)
# reformat model data frames so that the corrected r^2 values are all in the same
# data frame.
shapeH  = output_cor_shapeH$r
shapeV  = output_cor_shapeV$r
r_shape_all = data.frame(shapeH,shapeV) #r squared values for all participants for H & V slant responses
kable(r_shape_all) # prints the r^2 values
mean_and_median_table(r_shape_all) # prints the mean median and 95% CI
#run an unpaired t test to establish if the r values are statistically significantly
#different from zero
zero_array = integer(length(shapeV)) #list of zeros the length of the data
#add zeros to the table
r_shape_all_w0 = mutate(r_shape_all,zeros = zero_array)
# A routine to iterate over pairs of tests
map2_df(
c("shapeH","shapeV"),
c("zeros","zeros"),
run_unpaired_ttest_test,
data = r_shape_all_w0
) %>% #%>% takes this output and puts it into next
#
kable() #makes table come out as html
## Calculating r^2 for each of the models. This script gives you the corrected
## and uncorrected r^2 values (but it does not print the values)
#UNIFORM
freeparameter = 0 #no free parameter just calculating r^2
output_fit_shapeU = calculate_r2(ShapeU_actual_and_fit,freeparameter)
#save the matrix in the folder as a csv
write.csv(output_fit_shapeU, "G:/Shared drives/MagEffects/MagEffects/V1_FINAL/Data/Data_Analysis/Rstudio_analysis/r2_vals_fit_shapeU.csv", row.names=FALSE)
#HORIZONTAL
freeparameter = 0
output_fit_shapeH = calculate_r2(ShapeH_actual_and_fit,freeparameter)
#save the matrix in the folder as a csv
write.csv(output_fit_shapeH, "G:/Shared drives/MagEffects/MagEffects/V1_FINAL/Data/Data_Analysis/Rstudio_analysis/r2_vals_fit_shapeH.csv", row.names=FALSE)
#VERTICAL
freeparameter = 0
output_fit_shapeV = calculate_r2(ShapeV_actual_and_fit,freeparameter)
#save the matrix in the folder as a csv
write.csv(output_fit_shapeV, "G:/Shared drives/MagEffects/MagEffects/V1_FINAL/Data/Data_Analysis/Rstudio_analysis/r2_vals_fit_shapeV.csv", row.names=FALSE)
# reformat model data frames so that the corrected r^2 values are all in the same
# data frame.
shape_fit_U  = output_fit_shapeU$r2_adjusted
shape_fit_H  = output_fit_shapeH$r2_adjusted
shape_fit_V  = output_fit_shapeV$r2_adjusted
r2_adjusted_shape_fit_all = data.frame(shape_fit_U,shape_fit_H,shape_fit_V) #adjusted r2 for all models
kable(r2_adjusted_shape_fit_all) # prints the r^2 values
mean_and_median_table(r2_adjusted_shape_fit_all) # prints the mean median and 95% CI
#RUN UNPAIRD T TEST
# we want to evaluate if the r^2 values are greater than zero
#create an array of zeros to compare to the r^2 values
zero_array = integer(length(shape_fit_U)) #list of zeros the length of the data
#add zeros to the table
r2_adjusted_shape_fit_all_with0 = mutate(r2_adjusted_shape_fit_all,zeros = zero_array)
# A routine to iterate over pairs of tests
map2_df(
c("shape_fit_U","shape_fit_H","shape_fit_V"),
c("zeros","zeros","zeros"),
run_unpaired_ttest_test,
data = r2_adjusted_shape_fit_all_with0
) %>% #%>% takes this output and puts it into next
#Correct p values. this is performed after because we need all of the p values in
# one matrix to perform the correction
mutate( "Corrected P Value" = p.adjust("Original P Value", method = "fdr") ) %>% #adding a column for corrected p value
#
kable() #makes table come out as html
# We calculate RMSE as another way to assess the closeness of the results to our
# estimates
#horizontal
RMSE_fit_shapeH = calculate_rmse(ShapeH_actual_and_fit)
write.csv(RMSE_fit_shapeH$rmse, "G:/Shared drives/MagEffects/MagEffects/V1_FINAL/Data/Data_Analysis/Rstudio_analysis/RMSE_vals_fit_shapeH.csv", row.names=FALSE)
#vertical
RMSE_fit_shapeV = calculate_rmse(ShapeV_actual_and_fit)
write.csv(RMSE_fit_shapeV$rmse, "G:/Shared drives/MagEffects/MagEffects/V1_FINAL/Data/Data_Analysis/Rstudio_analysis/RMSE_vals_fit_shapeV.csv", row.names=FALSE)
#uniform
RMSE_fit_shapeU = calculate_rmse(ShapeU_actual_and_fit)
write.csv(RMSE_fit_shapeU$rmse, "G:/Shared drives/MagEffects/MagEffects/V1_FINAL/Data/Data_Analysis/Rstudio_analysis/RMSE_vals_fit_shapeU.csv", row.names=FALSE)
shape_U  = RMSE_fit_shapeU$rmse
shape_H  = RMSE_fit_shapeH$rmse
shape_V  = RMSE_fit_shapeV$rmse
rmse_adjusted_shape_fit_all = data.frame(shape_U,shape_H,shape_V) #adjusted r2 for all models
kable(rmse_adjusted_shape_fit_all) # prints the rmse values
mean_and_median_table(rmse_adjusted_shape_fit_all) # prints the mean median and 95% CI
#RUN UNPAIRD T TEST
# we want to evaluate if the RMSE values are greater than zero
#create an array of zeros to compare to the RMSE values
zero_array = integer(length(shape_fit_U)) #list of zeros the length of the data
#add zeros to the table
rmse_adjusted_shape_fit_all_with0 = mutate(rmse_adjusted_shape_fit_all,zeros = zero_array)
# A routine to iterate over pairs of tests
map2_df(
c("shape_U","shape_H","shape_V"),
c("zeros","zeros","zeros"),
run_unpaired_ttest_test,
data = rmse_adjusted_shape_fit_all_with0
) %>% #%>% takes this output and puts it into next
#Correct p values. this is performed after because we need all of the p values in
# one matrix to perform the correction
mutate( "Corrected P Value" = p.adjust("Original P Value", method = "fdr") ) %>% #adding a column for corrected p value
#
kable() #makes table come out as html
